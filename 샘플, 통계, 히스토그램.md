#### sample, take, takeSample 연산으로 RDD의 일부 요소 가져오기



scala> val s = uniquelds.sample(false, 0.3)
s: org.apache.spark.rdd.RDD[String] = PartitionwiseSampledRDD[15] at sample at <console>:25

scala> s.count
res13: Long = 0

scala> s.collect
res14: Array[String] = Array()

scala> val swr = uniquelds.sample(true, 0.5)
swr: org.apache.spark.rdd.RDD[String] = PartitionwiseSampledRDD[16] at sample at <console>:25

scala> swr.count
res15: Long = 3

scala> swr.collect
res16: Array[String] = Array(80, 98, 16)

scala> val taken = uniquelds.takeSample(false, 5)
taken: Array[String] = Array(77, 80, 98, 94, 31)

scala> uniquelds.take(3)
res17: Array[String] = Array(80, 20, 15)



#### double RDD 함수로 기초 통계량 계산



scala> intlds.mean
res18: Double = 44.785714285714285

scala> intlds.sum
res19: Double = 627.0

scala> intlds.variance
res20: Double = 1114.8826530612246

scala> intlds.stdev
res21: Double = 33.38985853610681



#### 히스토그램으로 데이터 분포 시각화



scala> intlds.histogram(Array(1.0, 50.0, 100.0))
res22: Array[Long] = Array(9, 5)

scala> intlds.histogram(3)
res23: (Array[Double], Array[Long]) = (Array(15.0, 42.66666666666667, 70.33333333333334, 98.0),Array(9, 0, 5))